import { unstable_getCacheForType, useTransition, unstable_useCacheRefresh, useCallback, useSyncExternalStore, useState, useEffect, useMemo, useRef } from 'react';
import { configure } from 'array-sorting-utilities';
import { configure as configure$1 } from 'interval-utilities';
import DataIntervalTree from 'node-interval-tree';
import { configure as configure$2 } from 'point-utilities';
import equal from 'deep-equal';

const STATUS_NOT_FOUND = "not-found";
const STATUS_PENDING = "pending";
const STATUS_ABORTED = "aborted";
const STATUS_REJECTED = "rejected";
const STATUS_RESOLVED = "resolved";

// A "thenable" is a subset of the Promise API.
// We could use a Promise as thenable, but Promises have a downside: they use the microtask queue.
// An advantage to creating a custom thenable is synchronous resolution (or rejection).
//
// A "deferred" is a "thenable" that has convenience resolve/reject methods.
function createDeferred(debugLabel) {
  let status = STATUS_PENDING;
  let rejectPromise;
  let resolvePromise;
  const promise = new Promise((resolve, reject) => {
    rejectPromise = reject;
    resolvePromise = resolve;
  });
  promise.catch(() => {
    // Prevent unhandled promise rejection warning.
  });
  function assertPending() {
    if (status !== STATUS_PENDING) {
      throw Error(`Deferred has already been ${status}`);
    }
  }
  const deferred = {
    // @ts-ignore
    debugLabel,
    promise,
    reject(error) {
      assertPending();
      status = STATUS_REJECTED;
      rejectPromise(error);
    },
    resolve(value) {
      assertPending();
      status = STATUS_RESOLVED;
      resolvePromise(value);
    },
    get status() {
      return status;
    }
  };
  return deferred;
}

function createPendingRecordData(deferred = createDeferred(), abortController = new AbortController()) {
  return {
    abortController,
    deferred,
    status: STATUS_PENDING
  };
}
function createRejectedRecordData(error) {
  return {
    error,
    status: STATUS_REJECTED
  };
}
function createResolvedRecordData(value, metadata = null) {
  return {
    metadata,
    status: STATUS_RESOLVED,
    value
  };
}

function createPendingRecord(deferred = createDeferred(), abortController = new AbortController()) {
  return {
    data: createPendingRecordData(deferred, abortController)
  };
}
function createRejectedRecord(error) {
  return {
    data: createRejectedRecordData(error)
  };
}
function createResolvedRecord(value) {
  return {
    data: createResolvedRecordData(value)
  };
}
function updateRecordToPending(record, deferred = createDeferred(), abortController = new AbortController()) {
  record.data = createPendingRecordData(deferred, abortController);
}
function updateRecordToRejected(record, error) {
  record.data = createRejectedRecordData(error);
}
function updateRecordToResolved(record, value) {
  record.data = createResolvedRecordData(value);
}

function assert(expectedCondition, message = "Assertion failed!") {
  if (!expectedCondition) {
    console.error(message);
    throw Error(message);
  }
}

function isPendingRecord(record) {
  return record.data.status === STATUS_PENDING;
}
function isPendingRecordData(recordData) {
  return recordData.status === STATUS_PENDING;
}
function isRejectedRecord(record) {
  return record.data.status === STATUS_REJECTED;
}
function isRejectedRecordData(recordData) {
  return recordData.status === STATUS_REJECTED;
}
function isResolvedRecord(record) {
  return record.data.status === STATUS_RESOLVED;
}
function isResolvedRecordData(recordData) {
  return recordData.status === STATUS_RESOLVED;
}

function assertPendingRecord(record) {
  assert(isPendingRecord(record));
  return true;
}
function assertPendingRecordData(recordData) {
  assert(isPendingRecordData(recordData));
  return true;
}
function assertRejectedRecord(record) {
  assert(isRejectedRecord(record));
  return true;
}
function assertRejectedRecordData(recordData) {
  assert(isRejectedRecordData(recordData));
  return true;
}
function assertResolvedRecord(record) {
  assert(isResolvedRecord(record));
  return true;
}
function assertResolvedRecordData(recordData) {
  assert(isResolvedRecordData(recordData));
  return true;
}

let enabled = false;
function disableDebugLogging() {
  enabled = false;
}
function enableDebugLogging() {
  enabled = true;
}
function log(enableDebugLogging = enabled, args) {
}

function defaultGetCache() {
  return new Map();
}

function defaultGetKey(...params) {
  return params.join(",");
}

function isPromiseLike(value) {
  return value != null && typeof value.then === "function";
}

if (unstable_getCacheForType == null) {
  throw new Error("unstable_getCacheForType is not a function.\n\n" + "This probably means that the wrong version of React has been specified as a dependency. " + 'The "suspense" package requires the @experimental release of "react" and "react-dom".\n\n' + "For more information, see https://react.dev/community/versioning-policy#experimental-channel");
}
function createCache(options) {
  let {
    config = {},
    debugLabel,
    debugLogging,
    getKey = defaultGetKey,
    load
  } = options;
  const {
    getCache = defaultGetCache,
    immutable = false
  } = config;
  const debugLog = (message, params, ...args) => {
    const cacheKey = params ? `"${getKey(params)}"` : "";
    const prefix = debugLabel ? `createCache[${debugLabel}]` : "createCache";
    log(debugLogging, [`%c${prefix}`, "font-weight: bold; color: yellow;", message, cacheKey, ...args]);
  };
  debugLog("Cache created");

  // This map enables selective mutations to be scheduled with React
  // (one record can be invalidated without affecting others)
  // Reads will query the map created by createRecordMap first,
  // and fall back to this map if no match is found
  const recordMap = getCache(onExternalCacheEviction);

  // Stores status of in-progress mutation
  // If no entry is present here, the Record map will be used instead
  // Storing this information separately enables status to be updated during mutation
  // without modifying the actual record (which may trigger an unintentional update/fallback)
  const mutationAbortControllerMap = new Map();

  // Stores a set of callbacks (by key) for status subscribers.
  const subscriberMap = new Map();

  // Immutable caches should read from backing cache directly.
  // Only mutable caches should use React-managed cache
  // in order to reduce re-renders when caches are refreshed for mutations.
  const getCacheForType = immutable ? () => recordMap : unstable_getCacheForType;
  function abort(...params) {
    const cacheKey = getKey(params);
    const pendingMutationRecordMap = getCacheForType(createPendingMutationRecordMap);

    // In-progress mutations aren't guaranteed to be in the recordMap.
    // So we check the mutationAbortControllerMap to infer this.
    const abortController = mutationAbortControllerMap.get(cacheKey);
    if (abortController) {
      debugLog("abort()", params);
      abortController.abort();
      notifySubscribers(params);
      return true;
    } else {
      const record = pendingMutationRecordMap.get(cacheKey) ?? recordMap.get(cacheKey);
      if (record && isPendingRecord(record)) {
        debugLog("abort()", params);
        pendingMutationRecordMap.delete(cacheKey);

        // Only delete the main cache if it's the same record/request
        // Aborting a mutation should not affect the main cache
        if (recordMap.get(cacheKey) === record) {
          recordMap.delete(cacheKey);
        }
        record.data.abortController.abort();
        notifySubscribers(params);
        return true;
      }
    }
    return false;
  }
  function cache(value, ...params) {
    debugLog("cache()", params);
    const cacheKey = getKey(params);
    const pendingMutationRecordMap = getCacheForType(createPendingMutationRecordMap);
    let record = getRecord(...params);
    if (record != null) {
      if (isPendingRecord(record)) {
        const {
          abortController,
          deferred
        } = record.data;
        abortController.abort();
        updateRecordToResolved(record, value);

        // Don't leave any pending request hanging
        deferred.resolve(value);
        notifySubscribers(params);
        return;
      }
    }
    record = createResolvedRecord(value);
    recordMap.set(cacheKey, record);
    pendingMutationRecordMap.set(cacheKey, record);
    notifySubscribers(params);
  }
  function createPendingMutationRecordMap() {
    return getCache(() => {
      // We don't really need to do anything here
      // This map will almost always be a subset of the recordMap
      // but we also don't want it to bypass the getCache() eviction logic (if any)
    });
  }
  function disableDebugLogging() {
    debugLogging = false;
  }
  function enableDebugLogging() {
    debugLogging = true;
  }
  function evict(...params) {
    const cacheKey = getKey(params);
    const pendingMutationRecordMap = getCacheForType(createPendingMutationRecordMap);
    debugLog("evict()", params);
    const didDelete = recordMap.delete(cacheKey);
    pendingMutationRecordMap.delete(cacheKey);
    notifySubscribers(params);
    return didDelete;
  }
  function evictAll() {
    const pendingMutationRecordMap = getCacheForType(createPendingMutationRecordMap);
    debugLog("evictAll()", undefined);
    recordMap.clear();
    pendingMutationRecordMap.clear();
    subscriberMap.forEach(set => {
      set.forEach(callback => {
        callback({
          status: STATUS_NOT_FOUND
        });
      });
    });
    subscriberMap.clear();
  }
  function getRecord(...params) {
    const cacheKey = getKey(params);
    const pendingMutationRecordMap = getCacheForType(createPendingMutationRecordMap);
    return pendingMutationRecordMap.get(cacheKey) ?? recordMap.get(cacheKey);
  }
  function getOrCreateRecord(...params) {
    const cacheKey = getKey(params);
    const pendingMutationRecordMap = getCacheForType(createPendingMutationRecordMap);
    let record = getRecord(...params);
    if (record == null) {
      debugLog("read() Cache miss", params);
      const abortController = new AbortController();
      const deferred = createDeferred(debugLabel ? `${debugLabel} ${cacheKey}` : cacheKey);
      record = createPendingRecord(deferred, abortController);
      recordMap.set(cacheKey, record);
      pendingMutationRecordMap.set(cacheKey, record);
      notifySubscribers(params);
      processPendingRecord(abortController.signal, record, ...params);
    } else {
      debugLog("read() Cache hit", params);
    }
    return record;
  }
  function getStatus(...params) {
    debugLog("getStatus()", params);
    const cacheKey = getKey(params);

    // Check for pending mutations first
    if (mutationAbortControllerMap.has(cacheKey)) {
      return STATUS_PENDING;
    }

    // Else fall back to Record status
    const record = recordMap.get(cacheKey);
    if (!record) {
      return STATUS_NOT_FOUND;
    } else if (isResolvedRecord(record)) {
      return record.data.status;
    }
    return record.data.status;
  }
  function getValue(...params) {
    debugLog("getValue()", params);
    const cacheKey = getKey(params);
    const record = recordMap.get(cacheKey);
    if (record == null) {
      throw Error("No record found");
    } else if (isRejectedRecord(record)) {
      throw record.data.error;
    } else if (isResolvedRecord(record)) {
      return record.data.value;
    } else {
      throw Error(`Record found with status "${record.data.status}"`);
    }
  }
  function getValueIfCached(...params) {
    debugLog("getValueIfCached()", params);
    const cacheKey = getKey(params);
    const record = recordMap.get(cacheKey);
    if (record && isResolvedRecord(record)) {
      return record.data.value;
    }
  }
  function onExternalCacheEviction(key) {
    const set = subscriberMap.get(key);
    if (set) {
      set.forEach(callback => {
        callback({
          status: STATUS_NOT_FOUND
        });
      });
    }
  }
  function prefetch(...params) {
    debugLog("prefetch()", params);
    try {
      const promiseOrValue = readAsync(...params);
      if (isPromiseLike(promiseOrValue)) {
        promiseOrValue.then(() => {}, error => {
          // Don't let readAsync throw an uncaught error.
        });
      }
    } catch {
      // Don't throw an already-cached error
    }
  }
  function readAsync(...params) {
    // getOrCreateRecord() will call debugLog (cache hit or miss)
    const record = getOrCreateRecord(...params);
    if (isPendingRecord(record)) {
      return record.data.deferred.promise;
    }
    if (isResolvedRecord(record)) {
      return record.data.value;
    }
    throw record.data.error;
  }
  function read(...params) {
    // getOrCreateRecord() will call debugLog (cache hit or miss)
    const record = getOrCreateRecord(...params);
    if (isPendingRecord(record)) {
      throw record.data.deferred.promise;
    } else if (isResolvedRecord(record)) {
      return record.data.value;
    } else {
      throw record.data.error;
    }
  }
  function getSubscriptionData(params) {
    const status = getStatus(...params);
    const record = getRecord(...params);
    if (status === STATUS_PENDING) {
      // Special case pending, async mutation
      return {
        status
      };
    }
    if (record) {
      if (isResolvedRecord(record)) {
        return {
          status: STATUS_RESOLVED,
          value: record.data.value
        };
      } else if (isRejectedRecord(record)) {
        return {
          error: record.data.error,
          status: STATUS_REJECTED
        };
      }
    }
    return {
      status: status
    };
  }
  function notifySubscribers(params, data) {
    const cacheKey = getKey(params);
    const set = subscriberMap.get(cacheKey);
    if (set) {
      if (data === undefined) {
        data = getSubscriptionData(params);
      }
      set.forEach(callback => {
        callback(data);
      });
    }
  }
  async function processPendingRecord(abortSignal, record, ...params) {
    assertPendingRecord(record);
    const {
      abortController,
      deferred
    } = record.data;
    try {
      const valueOrPromiseLike = load(params, abortController);
      const value = isPromiseLike(valueOrPromiseLike) ? await valueOrPromiseLike : valueOrPromiseLike;
      if (!abortSignal.aborted) {
        debugLog("read() Pending request resolved", params, value);
        updateRecordToResolved(record, value);
        deferred.resolve(value);
      }
    } catch (error) {
      if (!abortSignal.aborted) {
        debugLog("read() Pending request rejected", params, error);
        updateRecordToRejected(record, error);
        deferred.reject(error);
      }
    } finally {
      if (!abortSignal.aborted) {
        notifySubscribers(params);
      }
    }
  }
  function subscribe(callback, ...params) {
    debugLog("subscribe()", params);
    const cacheKey = getKey(params);
    let set = subscriberMap.get(cacheKey);
    if (set) {
      set.add(callback);
    } else {
      set = new Set([callback]);
      subscriberMap.set(cacheKey, set);
    }
    try {
      const data = getSubscriptionData(params);
      callback(data);
    } finally {
      return () => {
        set.delete(callback);
        if (set.size === 0) {
          subscriberMap.delete(cacheKey);
        }
      };
    }
  }
  const value = {
    // Internal API (used by useCacheMutation)
    __createPendingMutationRecordMap: createPendingMutationRecordMap,
    __getKey: getKey,
    __getOrCreateRecord: getOrCreateRecord,
    __isImmutable: () => immutable,
    __mutationAbortControllerMap: mutationAbortControllerMap,
    __notifySubscribers: notifySubscribers,
    __recordMap: recordMap,
    // Public API
    abort,
    cache,
    disableDebugLogging,
    enableDebugLogging,
    evict,
    evictAll,
    getStatus,
    getValue,
    getValueIfCached,
    readAsync,
    read,
    prefetch,
    subscribe: subscribe
  };
  return value;
}

function createExternallyManagedCache(options) {
  const {
    timeout,
    timeoutMessage = "Timed out",
    ...rest
  } = options;
  const decoratedCache = createCache({
    ...rest,
    load: async (params, loadOptions) => new Promise((resolve, reject) => {
      if (timeout != null) {
        setTimeout(() => {
          if (!loadOptions.signal.aborted) {
            reject(timeoutMessage);
          }
        }, timeout);
      }
    })
  });
  const {
    __getKey,
    __getOrCreateRecord,
    __notifySubscribers,
    __recordMap
  } = decoratedCache;
  const {
    cache,
    ...api
  } = decoratedCache;
  return {
    ...api,
    cacheError(error, ...params) {
      const key = __getKey(params);
      const record = __getOrCreateRecord(...params);
      if (isPendingRecord(record)) {
        const {
          abortController,
          deferred
        } = record.data;
        abortController.abort();
        updateRecordToRejected(record, error);

        // Don't leave any pending request hanging
        deferred.reject(error);
      }
      __recordMap.set(key, record);
      __notifySubscribers(params);
    },
    cacheValue(value, ...params) {
      const key = __getKey(params);
      const record = __getOrCreateRecord(...params);
      if (isPendingRecord(record)) {
        const {
          abortController,
          deferred
        } = record.data;
        abortController.abort();
        updateRecordToResolved(record, value);

        // Don't leave any pending request hanging
        deferred.resolve(value);
      }
      __recordMap.set(key, record);
      __notifySubscribers(params);
    }
  };
}

function findIntervals(cachedIntervals, targetInterval, intervalUtils) {
  let targetIntervals = [targetInterval];

  // Retry new intervals only if they are smaller than existing partial intervals
  // or if there's a partial overlap
  const retryIntersectingIntervals = cachedIntervals.partial.find(partialInterval => !intervalUtils.equals(partialInterval, targetInterval) && !intervalUtils.contains(targetInterval, partialInterval) && (intervalUtils.contains(partialInterval, targetInterval) || intervalUtils.intersects(partialInterval, targetInterval))) != null;

  // Find overlapping intervals containing partial results
  // Don't re-request those intervals unless requesting smaller ranges
  const {
    ab: partialAndRequestedIntervals,
    b: requestedIntervals
  } = intervalUtils.separateAll(cachedIntervals.partial, targetIntervals);

  // Find overlapping intervals containing failed results
  const {
    ab: failedIntervals
  } = intervalUtils.separateAll(cachedIntervals.failed, targetIntervals);
  targetIntervals = retryIntersectingIntervals ? intervalUtils.mergeAll(...partialAndRequestedIntervals, ...requestedIntervals) : requestedIntervals;
  const containsFailedResults = failedIntervals.length > 0;
  const containsPartialResults = !retryIntersectingIntervals && partialAndRequestedIntervals.length > 0;

  // Remove intervals that have already finished loading
  const {
    b: pendingOrNotLoadedIntervals
  } = intervalUtils.separateAll(cachedIntervals.loaded, targetIntervals);
  if (pendingOrNotLoadedIntervals.length === 0) {
    // Everything has already been loaded
    return {
      containsFailedResults,
      containsPartialResults,
      missing: [],
      pending: []
    };
  } else {
    // Separate the pending (in progress) intervals from the not-yet-loaded intervals
    const {
      b: missing,
      ab: pending
    } = intervalUtils.separateAll(cachedIntervals.pending, pendingOrNotLoadedIntervals);

    // Handle awkward edge cases by merging missing intervals
    // and filtering out any pending intervals that are contained within merged missing intervals
    const missingMerged = intervalUtils.mergeAll(...missing);
    const pendingFiltered = pending.filter(pendingInterval => {
      const contained = missingMerged.find(missingInterval => intervalUtils.contains(missingInterval, pendingInterval));
      return !contained;
    });
    return {
      containsFailedResults,
      containsPartialResults,
      missing: missingMerged,
      pending: pendingFiltered
    };
  }
}

function sliceValues(sortedValues, start, end, getPointForValue, pointUtils) {
  if (sortedValues.length === 0) {
    return [];
  }
  const sortedPoints = sortedValues.map(getPointForValue);
  const startIndex = pointUtils.findNearestIndexAfter(sortedPoints, start);
  const endIndex = pointUtils.findNearestIndexBefore(sortedPoints, end);
  return sortedValues.slice(startIndex, endIndex + 1);
}

function createIntervalCache(options) {
  let {
    debugLabel,
    debugLogging,
    getKey = defaultGetKey,
    getPointForValue,
    load
  } = options;
  const arraySortUtils = configure((a, b) => comparePoints(getPointForValue(a), getPointForValue(b)));
  const intervalUtils = configure$1(comparePoints);
  const pointUtils = configure$2(comparePoints);
  const metadataMap = new Map();

  // Subscribers are stored in a two-level data structure:
  // A key constructed from the params Array (getKey) points to an interval tree.
  // That interval tree maps an interval to a set of callbacks.
  const subscriberMap = new Map();
  const debugLog = (message, params, ...args) => {
    const cacheKey = params ? `"${getKey(...params)}"` : "";
    const prefix = debugLabel ? `createIntervalCache[${debugLabel}]` : "createIntervalCache";
    log(debugLogging, [`%c${prefix}`, "font-weight: bold; color: yellow;", message, cacheKey, ...args]);
  };
  debugLog("Cache created");
  function abort(...params) {
    debugLog("abort()", params);
    const metadataMapKey = getKey(...params);
    let caught;
    let metadata = metadataMap.get(metadataMapKey);
    if (metadata) {
      const {
        pendingMetadata
      } = metadata;
      if (pendingMetadata.length > 0) {
        const cloned = [...pendingMetadata];
        pendingMetadata.splice(0);
        for (let {
          interval,
          record
        } of cloned) {
          try {
            const [start, end] = interval;
            const recordKey = `${start}–${end}`;
            metadata.recordMap.delete(recordKey);
            record.data.abortController.abort();
            notifySubscribers(start, end, params);
          } catch (error) {
            caught = error;
          }
        }
        if (caught !== undefined) {
          throw caught;
        }
        return true;
      }
    }
    return false;
  }
  class PartialArray extends Array {
    constructor(length) {
      super(length);
      Object.defineProperty(this, "__partial", {
        value: true,
        enumerable: false
      });
    }
  }
  function arrayToPartialArray(values) {
    const partialArray = new PartialArray(values.length);
    values.forEach((value, index) => {
      partialArray[index] = value;
    });
    return partialArray;
  }
  function createCacheKey(start, end) {
    return `${start}–${end}`;
  }
  function disableDebugLogging() {
    debugLogging = false;
  }
  function enableDebugLogging() {
    debugLogging = true;
  }
  function evict(...params) {
    debugLog("evict()", params);
    const cacheKey = getKey(...params);
    const result = metadataMap.delete(cacheKey);
    const tree = subscriberMap.get(cacheKey);
    if (tree) {
      for (let node of tree.inOrder()) {
        node.data.callbacks.forEach(callback => callback({
          status: STATUS_NOT_FOUND
        }));
      }
    }
    return result;
  }
  function evictAll() {
    debugLog("evictAll()");
    const hadValues = metadataMap.size > 0;
    metadataMap.clear();
    subscriberMap.forEach(tree => {
      for (let node of tree.inOrder()) {
        node.data.callbacks.forEach(callback => callback({
          status: STATUS_NOT_FOUND
        }));
      }
    });
    return hadValues;
  }
  function getOrCreateIntervalMetadata(...params) {
    const cacheKey = getKey(...params);
    let metadata = metadataMap.get(cacheKey);
    if (metadata == null) {
      metadata = {
        intervals: {
          failed: [],
          loaded: [],
          partial: []
        },
        pendingMetadata: [],
        recordMap: new Map(),
        sortedValues: []
      };
      metadataMap.set(cacheKey, metadata);
    }
    return metadata;
  }
  function getOrCreateRecord(start, end, ...params) {
    const metadata = getOrCreateIntervalMetadata(...params);
    const cacheKey = createCacheKey(start, end);
    let record = metadata.recordMap.get(cacheKey);
    if (record == null) {
      debugLog(`read(${start}, ${end}) Cache miss`, params);
      const abortController = new AbortController();
      const deferred = createDeferred(debugLabel ? `${debugLabel}: ${cacheKey}` : `${cacheKey}`);
      record = {
        data: {
          abortController,
          deferred,
          status: STATUS_PENDING
        }
      };
      metadata.recordMap.set(cacheKey, record);
      notifySubscribers(start, end, params);
      processPendingRecord(metadata, record, start, end, ...params);
    } else {
      debugLog(`read(${start}, ${end}) Cache hit`, params);
    }
    return record;
  }
  function getStatus(start, end, ...params) {
    debugLog(`getStatus(${start}, ${end})`, params);
    const metadata = getOrCreateIntervalMetadata(...params);
    const cacheKey = createCacheKey(start, end);
    let record = metadata.recordMap.get(cacheKey);
    if (!record) {
      // If there is no exact match, we may also still be within a larger interval.
      const {
        containsFailedResults,
        missing,
        pending
      } = findIntervals({
        failed: metadata.intervals.failed,
        loaded: metadata.intervals.loaded,
        partial: metadata.intervals.partial,
        pending: metadata.pendingMetadata.map(({
          interval
        }) => interval)
      }, [start, end], intervalUtils);
      if (pending.length > 0) {
        return STATUS_PENDING;
      } else if (containsFailedResults) {
        return STATUS_REJECTED;
      } else if (missing.length > 0) {
        return STATUS_NOT_FOUND;
      } else {
        return STATUS_RESOLVED;
      }
    }
    return record.data.status;
  }
  function getAlreadyLoadedValues(start, end, metadata) {
    const {
      containsFailedResults,
      containsPartialResults,
      missing
    } = findIntervals({
      failed: metadata.intervals.failed,
      loaded: metadata.intervals.loaded,
      partial: metadata.intervals.partial,
      pending: metadata.pendingMetadata.map(({
        interval
      }) => interval)
    }, [start, end], intervalUtils);
    if (missing.length === 0) {
      if (!containsFailedResults) {
        const value = sliceValues(metadata.sortedValues, start, end, getPointForValue, pointUtils);
        if (containsPartialResults) {
          return arrayToPartialArray(value);
        } else {
          return value;
        }
      }
    }
  }
  function getValue(start, end, ...params) {
    debugLog(`getValue(${start}, ${end})`, params);
    const metadata = getOrCreateIntervalMetadata(...params);
    const cacheKey = createCacheKey(start, end);
    const record = metadata.recordMap.get(cacheKey);
    if (record == null) {
      const value = getAlreadyLoadedValues(start, end, metadata);
      if (value) {
        return value;
      } else {
        throw Error("No record found");
      }
    } else if (isRejectedRecord(record)) {
      throw record.data.error;
    } else if (isResolvedRecord(record)) {
      return record.data.value;
    } else {
      throw Error(`Record found with status "${record.data.status}"`);
    }
  }
  function getValueIfCached(start, end, ...params) {
    debugLog(`getValueIfCached(${start}, ${end})`, params);
    const metadata = getOrCreateIntervalMetadata(...params);
    const cacheKey = createCacheKey(start, end);
    const record = metadata.recordMap.get(cacheKey);
    if (record == null) {
      return getAlreadyLoadedValues(start, end, metadata);
    } else if (isResolvedRecord(record)) {
      return record.data.value;
    }
  }
  function isPartialResult(value) {
    return value instanceof PartialArray;
  }
  function getSubscriptionData(start, end, params) {
    const metadata = getOrCreateIntervalMetadata(...params);
    const cacheKey = createCacheKey(start, end);
    let record = metadata.recordMap.get(cacheKey);
    if (record) {
      if (isResolvedRecord(record)) {
        return {
          status: STATUS_RESOLVED,
          value: record.data.value
        };
      } else if (isRejectedRecord(record)) {
        return {
          error: record.data.error,
          status: STATUS_REJECTED
        };
      }
    }
    const status = getStatus(start, end, ...params);
    return {
      status: status
    };
  }
  function notifySubscribers(start, end, params) {
    const cacheKey = getKey(...params);
    const tree = subscriberMap.get(cacheKey);
    if (tree) {
      const matches = tree.search(start, end);
      matches.forEach(match => {
        const data = getSubscriptionData(match.start, match.end, match.params);
        match.callbacks.forEach(callback => {
          callback(data);
        });
      });
    }
  }
  async function processPendingInterval(metadata, pendingMetadata, start, end) {
    const {
      record,
      value
    } = pendingMetadata;
    assertPendingRecord(record);
    const {
      abortController
    } = record.data;
    let values;
    try {
      values = isPromiseLike(value) ? await value : value;
      if (abortController.signal.aborted) {
        // Ignore results if the request was aborted
        return;
      }

      // Store partially loaded intervals separately;
      // Future requests that contain them should also be flagged as partial
      if (isPartialResult(values)) {
        pendingMetadata.containsPartialResults();
        metadata.intervals.partial = intervalUtils.mergeAll(...intervalUtils.sort(...metadata.intervals.partial, [start, end]));
      } else {
        metadata.intervals.loaded = intervalUtils.mergeAll(...intervalUtils.sort(...metadata.intervals.loaded, [start, end]));

        // Prune partials interval to remove ones that have been newly loaded
        // note this intentionally includes intersections.
        // The thinking behind this is as follows:
        // 1. Loading part of a previously partial range
        //    might reduce the range enough so that the remainder can be fully loaded
        // 2. If we don't shrink partial intervals as we refine them,
        //    it may become impossible to fully remove them in some cases.
        for (let index = metadata.intervals.partial.length - 1; index >= 0; index--) {
          const partialInterval = metadata.intervals.partial[index];
          if (intervalUtils.intersects([start, end], partialInterval)) {
            metadata.intervals.partial.splice(index, 1);
            const cacheKey = createCacheKey(partialInterval[0], partialInterval[1]);
            metadata.recordMap.delete(cacheKey);
          }
        }
      }

      // Merge in newly-loaded values; don't add duplicates though.
      // Duplicates may slip in at the edges (because of how intervals are split)
      // or they may be encountered as ranges of partial results are refined.
      for (let index = 0; index < values.length; index++) {
        const value = values[index];
        const insertIndex = arraySortUtils.findInsertIndex(metadata.sortedValues, value);
        const itemAtIndex = metadata.sortedValues[insertIndex];
        if (itemAtIndex == null || comparePoints(getPointForValue(itemAtIndex), getPointForValue(value)) !== 0) {
          metadata.sortedValues.splice(insertIndex, 0, value);
        }
      }
    } catch (error) {
      // Ignore the error here; the caller will handle it.

      metadata.intervals.failed = intervalUtils.mergeAll(...intervalUtils.sort(...metadata.intervals.failed, [start, end]));
    } finally {
      const index = metadata.pendingMetadata.indexOf(pendingMetadata);
      metadata.pendingMetadata.splice(index, 1);
    }
  }
  async function processPendingRecord(metadata, record, start, end, ...params) {
    assertPendingRecord(record);
    const {
      abortController,
      deferred
    } = record.data;
    const {
      signal
    } = abortController;
    const foundIntervals = findIntervals({
      failed: metadata.intervals.failed,
      loaded: metadata.intervals.loaded,
      partial: metadata.intervals.partial,
      pending: metadata.pendingMetadata.map(({
        interval
      }) => interval)
    }, [start, end], intervalUtils);

    // If any of the unloaded intervals contain a failed request,
    // we shouldn't try loading them again
    // This is admittedly somewhat arbitrary but matches Replay's functionality
    const previouslyFailedInterval = foundIntervals.missing.find(missingInterval => metadata.intervals.failed.find(interval => intervalUtils.contains(missingInterval, interval)));
    if (previouslyFailedInterval != null) {
      const error = Error("Cannot load interval that contains previously failed interval");
      record.data = {
        error,
        status: STATUS_REJECTED
      };
      deferred.reject(error);
      notifySubscribers(start, end, params);
      return;
    }
    let containsPartialResults = false;
    const missingPromiseLikes = [];
    foundIntervals.missing.forEach(([start, end]) => {
      const options = {
        returnAsPartial: arrayToPartialArray,
        signal: abortController.signal
      };
      const thenable = load(start, end, ...params, options);
      missingPromiseLikes.push(thenable);
      const pendingMetadata = {
        containsPartialResults: () => {
          containsPartialResults = true;
        },
        interval: [start, end],
        record: record,
        value: thenable
      };
      metadata.pendingMetadata.push(pendingMetadata);
      processPendingInterval(metadata, pendingMetadata, start, end);
    });

    // Gather all of the deferred requests the new interval blocks on.
    // Can we make this more efficient than a nested loop?
    // It's tricky since requests initiated separately (e.g. [1,2] and [2,4])
    // may end up reported as single/merged blocker (e.g. [1,3])
    const pendingPromiseLikes = [];
    foundIntervals.pending.forEach(([start, end]) => {
      metadata.pendingMetadata.forEach(({
        interval,
        value
      }) => {
        if (intervalUtils.contains(interval, [start, end])) {
          pendingPromiseLikes.push(value);
        }
      });
    });
    try {
      const values = await Promise.all([...missingPromiseLikes, ...pendingPromiseLikes]);
      if (!signal.aborted) {
        let value = sliceValues(metadata.sortedValues, start, end, getPointForValue, pointUtils);
        if (containsPartialResults) {
          value = arrayToPartialArray(value);
        }
        record.data = {
          metadata: {
            containsPartialResults
          },
          status: STATUS_RESOLVED,
          value
        };
        debugLog(`read() Pending request resolved (${start}, ${end})`, params, values);
        deferred.resolve(value);
        notifySubscribers(start, end, params);
      }
    } catch (error) {
      let errorMessage = "Unknown Error";
      if (typeof error === "string") {
        errorMessage = error;
      } else if (error instanceof Error) {
        errorMessage = error.message;
      }
      debugLog(`read() Pending request rejected (${start}, ${end})`, params, errorMessage);
      if (!signal.aborted) {
        record.data = {
          error,
          status: STATUS_REJECTED
        };
        deferred.reject(error);
        notifySubscribers(start, end, params);
      }
    }
  }
  function read(start, end, ...params) {
    // getOrCreateRecord() will call debugLog (cache hit or miss)
    const record = getOrCreateRecord(start, end, ...params);
    if (record.data.status === STATUS_RESOLVED) {
      return record.data.value;
    } else if (isPendingRecord(record)) {
      throw record.data.deferred.promise;
    } else {
      throw record.data.error;
    }
  }
  function readAsync(start, end, ...params) {
    // getOrCreateRecord() will call debugLog (cache hit or miss)
    const record = getOrCreateRecord(start, end, ...params);
    switch (record.data.status) {
      case STATUS_PENDING:
        return record.data.deferred.promise;
      case STATUS_RESOLVED:
        return record.data.value;
      case STATUS_REJECTED:
        throw record.data.error;
    }
  }
  function subscribe(callback, start, end, ...params) {
    debugLog(`subscribe(${start}, ${end})`, params);
    const cacheKey = getKey(...params);
    let tree = subscriberMap.get(cacheKey);
    if (tree == null) {
      tree = new DataIntervalTree();
      subscriberMap.set(cacheKey, tree);
    }
    let match = tree.search(start, end).find(match => match.start === start && match.end === end);
    if (match) {
      match.callbacks.add(callback);
    } else {
      match = {
        callbacks: new Set([callback]),
        end,
        params,
        start
      };
      tree.insert(start, end, match);
    }
    try {
      const data = getSubscriptionData(match.start, match.end, match.params);
      callback(data);
    } finally {
      return () => {
        if (tree && match) {
          match.callbacks.delete(callback);
          if (match.callbacks.size === 0) {
            tree.remove(start, end, match);
          }
        }
      };
    }
  }
  return {
    abort,
    disableDebugLogging,
    enableDebugLogging,
    evict,
    evictAll,
    getStatus,
    getValue,
    getValueIfCached,
    isPartialResult,
    readAsync,
    read,
    subscribe
  };
}
function comparePoints(a, b) {
  return Number(a - b);
}

const key = Symbol.for("createSingleEntryCache").toString();
function createSingleEntryCache(options) {
  if (options.hasOwnProperty("getKey")) {
    throw Error("createSingleEntryCache does not support a getKey option");
  }
  return createCache({
    getKey: () => key,
    ...options
  });
}

function createStreamingCache(options) {
  let {
    debugLabel,
    debugLogging,
    getKey = defaultGetKey,
    load
  } = options;
  const debugLog = (message, params, ...args) => {
    const cacheKey = params ? `"${getKey(...params)}"` : "";
    const prefix = debugLabel ? `createCache[${debugLabel}]` : "createCache";
    log(debugLogging, [`%c${prefix}`, "font-weight: bold; color: yellow;", message, cacheKey, ...args]);
  };
  debugLog("Cache created");
  const abortControllerMap = new Map();
  const streamingValuesMap = new Map();
  function abort(...params) {
    debugLog("abort()", params);
    const cacheKey = getKey(...params);
    let abortController = abortControllerMap.get(cacheKey);
    if (abortController != null) {
      abortController.abort();
      return true;
    }
    return false;
  }
  function disableDebugLogging() {
    debugLogging = false;
  }
  function enableDebugLogging() {
    debugLogging = true;
  }
  function evict(...params) {
    debugLog("evict()", params);
    const cacheKey = getKey(...params);
    return streamingValuesMap.delete(cacheKey);
  }
  function evictAll() {
    debugLog("evictAll()");
    const hadValues = streamingValuesMap.size > 0;
    streamingValuesMap.clear();
    return hadValues;
  }
  function getOrCreateStreamingValue(...params) {
    const cacheKey = getKey(...params);
    let cached = streamingValuesMap.get(cacheKey);
    if (cached == null) {
      debugLog("stream() Cache miss", params);
      const deferred = createDeferred(debugLabel ? `${debugLabel}: ${cacheKey}` : cacheKey);
      const subscribers = new Set();
      const streamingValues = {
        complete: false,
        data: undefined,
        error: undefined,
        progress: undefined,
        resolver: deferred.promise,
        status: STATUS_PENDING,
        subscribe: callback => {
          subscribers.add(callback);
          return () => {
            subscribers.delete(callback);
          };
        },
        value: undefined
      };
      const notifySubscribers = () => {
        subscribers.forEach(subscriber => {
          try {
            subscriber();
          } catch (error) {}
        });
      };
      const assertPending = () => {
        if (streamingValues.status !== STATUS_PENDING) {
          throw Error(`Stream with status "${streamingValues.status}" cannot be updated`);
        }
      };
      const abortController = new AbortController();
      abortController.signal.addEventListener("abort", () => {
        if (streamingValues.complete) {
          return false;
        }
        debugLog(`stream() Pending request aborted`, params);
        streamingValues.status = STATUS_ABORTED;
        streamingValuesMap.delete(cacheKey);
        notifySubscribers();
        deferred.resolve();
      });
      abortControllerMap.set(cacheKey, abortController);
      const options = {
        update: (value, progress, data) => {
          assertPending();
          streamingValues.data = data == undefined ? streamingValues.data : data;
          streamingValues.value = value;
          if (progress != null) {
            streamingValues.progress = progress;
          }
          notifySubscribers();
        },
        resolve: () => {
          debugLog(`stream() Pending request resolved`, params);
          assertPending();
          streamingValues.complete = true;
          streamingValues.progress = 1;
          streamingValues.status = STATUS_RESOLVED;
          notifySubscribers();
          deferred.resolve(streamingValues);
        },
        reject: error => {
          debugLog(`stream() Pending request rejected`, params);
          assertPending();
          streamingValues.complete = true;
          streamingValues.error = error;
          streamingValues.status = STATUS_REJECTED;
          notifySubscribers();
          deferred.reject(error);
        },
        signal: abortController.signal
      };
      streamingValuesMap.set(cacheKey, streamingValues);
      loadAndCatchErrors(cacheKey, streamingValues, options, ...params);
      return streamingValues;
    }
    debugLog("stream() Cache hit", params);
    return cached;
  }
  function prefetch(...params) {
    debugLog("prefetch()", params);
    getOrCreateStreamingValue(...params);
  }
  function read(...params) {
    const {
      data,
      error,
      status,
      resolver,
      value
    } = stream(...params);
    switch (status) {
      case STATUS_PENDING:
        throw resolver;
      case STATUS_REJECTED:
        throw error;
      case STATUS_RESOLVED:
        assert(value != null);
        return {
          data,
          value
        };
      default:
        throw new Error(`Unexpected cache status "${status}"`);
    }
  }
  async function readAsync(...params) {
    const {
      resolver
    } = stream(...params);
    const {
      data,
      value
    } = await resolver;
    return {
      data,
      value
    };
  }
  function stream(...params) {
    // getOrCreateStreamingValue() will call debugLog (cache hit or miss)
    return getOrCreateStreamingValue(...params);
  }
  async function loadAndCatchErrors(cacheKey, streamingValues, options, ...params) {
    try {
      await load(options, ...params);
    } catch (error) {
      if (streamingValues.status === STATUS_PENDING) {
        options.reject(error);
      }
    } finally {
      abortControllerMap.delete(cacheKey);
    }
  }
  return {
    abort,
    disableDebugLogging,
    enableDebugLogging,
    evict,
    evictAll,
    prefetch,
    read,
    readAsync,
    stream
  };
}

function useCacheMutation(cache) {
  const {
    __createPendingMutationRecordMap: createPendingMutationRecordMap,
    __getKey: getKey,
    __isImmutable: isImmutable,
    __mutationAbortControllerMap: mutationAbortControllerMap,
    __notifySubscribers: notifySubscribers,
    __recordMap: recordMap
  } = cache;
  assert(!isImmutable(), "Cannot mutate an immutable cache");
  const [isPending, startTransition] = useTransition();
  const refresh = unstable_useCacheRefresh();
  const mutateSync = useCallback((params, newValue) => {
    const cacheKey = getKey(params);
    if (mutationAbortControllerMap.has(cacheKey)) {
      const abortController = mutationAbortControllerMap.get(cacheKey);
      abortController.abort();
      mutationAbortControllerMap.delete(cacheKey);
    }
    const record = createResolvedRecord(newValue);
    recordMap.set(cacheKey, record);
    const pendingMutationRecordMap = createPendingMutationRecordMap();
    pendingMutationRecordMap.set(cacheKey, record);
    startTransition(() => {
      refresh(createPendingMutationRecordMap, pendingMutationRecordMap);
    });
    notifySubscribers(params);
  }, [refresh, startTransition]);
  const mutateAsync = useCallback(async (params, callback) => {
    const cacheKey = getKey(params);
    if (mutationAbortControllerMap.has(cacheKey)) {
      const abortController = mutationAbortControllerMap.get(cacheKey);
      abortController.abort();
      mutationAbortControllerMap.delete(cacheKey);
    }
    const abortController = new AbortController();
    const deferred = createDeferred();
    let record = {
      data: {
        abortController,
        deferred,
        status: STATUS_PENDING
      }
    };

    // Don't mutate the module-level cache yet;
    // this might cause other components to suspend (and fallback)
    // if they happened to re-render before the mutation finished
    const pendingMutationRecordMap = createPendingMutationRecordMap();
    pendingMutationRecordMap.set(cacheKey, record);
    mutationAbortControllerMap.set(cacheKey, abortController);
    startTransition(() => {
      refresh(createPendingMutationRecordMap, pendingMutationRecordMap);
    });
    notifySubscribers(params, {
      status: STATUS_PENDING
    });
    try {
      // Wait until the mutation finishes or is aborted
      const newValue = await Promise.race([callback(), new Promise(resolve => {
        abortController.signal.onabort = () => resolve();
      })]);
      if (abortController.signal.aborted) {
        // The mutation was aborted;
        // if we can restore the previous record, do it
        const backupRecord = recordMap.get(cacheKey);
        if (backupRecord) {
          pendingMutationRecordMap.set(cacheKey, backupRecord);
        } else {
          pendingMutationRecordMap.delete(cacheKey);
        }
      } else {
        // This method determines whether to store the value in a WeakRef
        updateRecordToResolved(record, newValue);
        deferred.resolve(newValue);
        recordMap.set(cacheKey, record);
      }
      startTransition(() => {
        refresh(createPendingMutationRecordMap, pendingMutationRecordMap);
      });
      notifySubscribers(params, {
        status: STATUS_RESOLVED,
        value: newValue
      });
    } catch (error) {
      record.data = {
        error,
        status: STATUS_REJECTED
      };
      try {
        deferred.reject(error);
        await deferred.promise;
      } catch (error) {
        // Don't trigger an unhandled rejection
      }
      recordMap.set(cacheKey, record);
      startTransition(() => {
        refresh(createPendingMutationRecordMap, pendingMutationRecordMap);
      });
      notifySubscribers(params, {
        error,
        status: STATUS_REJECTED
      });
    } finally {
      // Cleanup after mutation by deleting the abort controller
      // If this mutation has already been preempted by a newer mutation
      // don't delete the newer controller
      if (abortController === mutationAbortControllerMap.get(cacheKey)) {
        mutationAbortControllerMap.delete(cacheKey);
      }
    }
  }, [refresh, startTransition]);
  return {
    isPending,
    mutateAsync,
    mutateSync
  };
}
useCacheMutation.displayName = "useCacheMutation";

function useCacheStatus(cache, ...params) {
  return useSyncExternalStore(callback => cache.subscribe(callback, ...params), () => cache.getStatus(...params), () => cache.getStatus(...params));
}
useCacheStatus.displayName = "useCacheStatus";

function useImperativeCacheValue(cache, ...params) {
  const status = useCacheStatus(cache, ...params);
  const [prevParams, setPrevParams] = useState(undefined);
  const [prevValue, setPrevValue] = useState(undefined);
  let error = undefined;
  let value = undefined;
  useEffect(() => {
    switch (status) {
      case STATUS_NOT_FOUND:
        {
          cache.prefetch(...params);
          break;
        }
      case STATUS_RESOLVED:
        {
          // Cache most recently resolved value in case of a mutation
          setPrevParams(prevParams => {
            if (prevParams == params || equal(prevParams, params)) {
              return prevParams;
            } else {
              return params;
            }
          });
          const value = cache.getValue(...params);
          setPrevValue(prevValue => {
            if (prevValue == value || equal(prevValue, value)) {
              return prevValue;
            } else {
              return value;
            }
          });
          break;
        }
    }
  }, [cache, status, ...params]);
  switch (status) {
    case STATUS_REJECTED:
      {
        try {
          cache.getValue(...params);
        } catch (caught) {
          error = caught;
        }
        break;
      }
    case STATUS_RESOLVED:
      {
        value = cache.getValue(...params);
        break;
      }
    case STATUS_PENDING:
      {
        value = prevParams == params || equal(prevParams, params) ? prevValue : undefined;
        break;
      }
  }
  return useMemo(() => ({
    error,
    status,
    value
  }), [error, status, value]);
}
useImperativeCacheValue.displayName = "useImperativeCacheValue";

function useIntervalCacheStatus(cache, start, end, ...params) {
  return useSyncExternalStore(callback => cache.subscribe(callback, start, end, ...params), () => cache.getStatus(start, end, ...params), () => cache.getStatus(start, end, ...params));
}
useIntervalCacheStatus.displayName = "useIntervalCacheStatus";

function useImperativeIntervalCacheValues(cache, start, end, ...params) {
  const status = useIntervalCacheStatus(cache, start, end, ...params);
  useEffect(() => {
    switch (status) {
      case STATUS_NOT_FOUND:
        cache.readAsync(start, end, ...params);
    }
  }, [cache, status, start, end, ...params]);
  switch (status) {
    case STATUS_REJECTED:
      let caught;
      try {
        cache.getValue(start, end, ...params);
      } catch (error) {
        caught = error;
      }
      return {
        error: caught,
        status: STATUS_REJECTED,
        value: undefined
      };
    case STATUS_RESOLVED:
      try {
        const value = cache.getValue(start, end, ...params);
        const isPartialResult = cache.isPartialResult(value);
        return {
          error: undefined,
          isPartialResult,
          status: STATUS_RESOLVED,
          value
        };
      } catch (error) {}
  }
  return {
    error: undefined,
    status: STATUS_PENDING,
    value: undefined
  };
}
useImperativeIntervalCacheValues.displayName = "useImperativeIntervalCacheValues";

function throttle(callback, throttleByAmount) {
  let lastCalledAt = -Infinity;
  let timeoutId = null;
  const throttled = (...args) => {
    const elapsed = performance.now() - lastCalledAt;
    if (elapsed >= throttleByAmount) {
      lastCalledAt = performance.now();
      callback(...args);
    } else {
      if (timeoutId) {
        clearTimeout(timeoutId);
      }
      timeoutId = setTimeout(() => {
        lastCalledAt = performance.now();
        callback(...args);
      }, throttleByAmount - elapsed);
    }
  };
  throttled.cancel = () => {
    if (timeoutId) {
      clearTimeout(timeoutId);
    }
  };
  return throttled;
}

function useStreamingValue(streamingValues, options = {}) {
  const {
    throttleUpdatesBy = 150
  } = options;
  const ref = useRef({
    complete: false,
    data: undefined,
    error: undefined,
    progress: 0,
    status: STATUS_PENDING,
    value: undefined
  });
  const getValue = () => {
    const value = ref.current;
    if (value.complete !== streamingValues.complete || value.data !== streamingValues.data || value.progress !== streamingValues.progress || value.status !== streamingValues.status || value.value !== streamingValues.value) {
      ref.current = {
        complete: streamingValues.complete,
        data: streamingValues.data,
        error: streamingValues.error,
        progress: streamingValues.progress,
        status: streamingValues.status,
        value: streamingValues.value
      };
    }
    return ref.current;
  };
  const throttledSubscribe = useCallback(callback => {
    const callbackWrapper = throttle(() => {
      callback();
    }, throttleUpdatesBy);
    return streamingValues.subscribe(callbackWrapper);
  }, [streamingValues.subscribe]);
  return useSyncExternalStore(throttledSubscribe, getValue, getValue);
}
useStreamingValue.displayName = "useStreamingValue";

function createInfallibleCache(suspenseCache) {
  return function createInfallibleSuspenseCache(...params) {
    try {
      return suspenseCache(...params);
    } catch (errorOrPromiseLike) {
      if (isPromiseLike(errorOrPromiseLike)) {
        throw errorOrPromiseLike;
      } else {
        return undefined;
      }
    }
  };
}

// Helper function to read from multiple Suspense caches in parallel.
// This method will re-throw any thrown value, but only after also calling subsequent caches.
function parallelize(...callbacks) {
  const values = [];
  let thrownValue = null;
  callbacks.forEach(callback => {
    try {
      values.push(callback());
    } catch (error) {
      thrownValue = error;
    }
  });
  if (thrownValue !== null) {
    throw thrownValue;
  }
  return values;
}

class WeakRefMap {
  constructor(finalizerCallback) {
    this.finalizerCallback = finalizerCallback;
    this.map = new Map();
    this.finalizationRegistry = new FinalizationRegistry(key => {
      this.map.delete(key);
      finalizerCallback(key);
    });
  }
  unregister(key) {
    const weakRef = this.map.get(key);
    if (weakRef) {
      const value = weakRef.deref();
      if (value != null) {
        this.finalizationRegistry.unregister(value);
      }
    }
  }
  delete(key) {
    const result = this.map.delete(key);
    this.unregister(key);
    return result;
  }
  get(key) {
    const weakRef = this.map.get(key);
    return weakRef ? weakRef.deref() : undefined;
  }
  has(key) {
    // Don't just use map.has(key) in case value has been GC'ed
    // and FinalizationRegistry callback has not yet run.
    const weakRef = this.map.get(key);
    return weakRef != null && weakRef.deref() != null;
  }
  set(key, value) {
    if (this.map.has(key)) {
      this.unregister(key);

      // FinalizationRegistry won't trigger if we unregister.
      this.finalizerCallback(key);
    }
    this.map.set(key, new WeakRef(value));
    if (value != null) {
      this.finalizationRegistry.register(value, key, value);
    }
    return this;
  }
  clear() {
    this.map.clear();
  }
}

export { STATUS_ABORTED, STATUS_NOT_FOUND, STATUS_PENDING, STATUS_REJECTED, STATUS_RESOLVED, WeakRefMap, assertPendingRecord, assertPendingRecordData, assertRejectedRecord, assertRejectedRecordData, assertResolvedRecord, assertResolvedRecordData, createCache, createDeferred, createExternallyManagedCache, createInfallibleCache, createIntervalCache, createPendingRecord, createPendingRecordData, createRejectedRecord, createRejectedRecordData, createResolvedRecord, createResolvedRecordData, createSingleEntryCache, createStreamingCache, disableDebugLogging, enableDebugLogging, isPendingRecord, isPendingRecordData, isPromiseLike, isRejectedRecord, isRejectedRecordData, isResolvedRecord, isResolvedRecordData, log, parallelize, updateRecordToPending, updateRecordToRejected, updateRecordToResolved, useCacheMutation, useCacheStatus, useImperativeCacheValue, useImperativeIntervalCacheValues, useIntervalCacheStatus, useStreamingValue };
